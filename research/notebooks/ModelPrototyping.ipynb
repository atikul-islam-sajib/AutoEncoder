{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import joblib\n",
    "import yaml\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from torchview import draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params():\n",
    "    with open(\"../../default_params.yml\", \"r\") as file:\n",
    "        return yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(value = None, filename = None):\n",
    "    if (value is not None):\n",
    "        joblib.dump(value = value, filename = filename)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"The value is empty. Please check the value and try again.\")\n",
    "    \n",
    "    \n",
    "def load(filename):\n",
    "    if filename is not None:\n",
    "        return joblib.load(filename = filename)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"The filename is empty. Please check the filename and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    def __init__(self, image_path = None, image_size = 128, batch_size = 1, split_size = 0.20):\n",
    "        self.image_path = image_path\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.split_size = split_size\n",
    "\n",
    "        self.sharp_images = []\n",
    "        self.blurred_images = []\n",
    "\n",
    "        try:\n",
    "            self.config = params()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"The config file is not valid. Please check the file and try again.\".capitalize())\n",
    "\n",
    "    def unzip_folder(self):\n",
    "        if os.path.exists(self.config[\"path\"][\"raw_path\"]):\n",
    "            with zipfile.ZipFile(self.image_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(os.path.join(self.config[\"path\"][\"raw_path\"], \"dataset\"))\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError(\"The raw data folder does not exist. Please check the path and try again.\")\n",
    "        \n",
    "    \n",
    "    def split_images(self, **kwargs):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            kwargs[\"X\"], kwargs[\"y\"], test_size=self.split_size, random_state=42\n",
    "            )\n",
    "        \n",
    "        return {\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test}\n",
    "\n",
    "    def transforms(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.CenterCrop((self.image_size, self.image_size)),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def feature_extractor(self):\n",
    "        if os.path.exists(self.config[\"path\"][\"raw_path\"]):\n",
    "            self.directory = os.path.join(self.config[\"path\"][\"raw_path\"], \"dataset\")\n",
    "            self.sharp = [\"sharp\"]\n",
    "\n",
    "            blurred_image = os.path.join(self.directory, \"blurred\")\n",
    "\n",
    "            for category in self.sharp:\n",
    "                path = os.path.join(self.directory, category)\n",
    "\n",
    "                for image in os.listdir(path):\n",
    "                    sharp_image_number = image.split(\"_\")[0]\n",
    "\n",
    "                    for blur_image in os.listdir(blurred_image):\n",
    "                        blurred_image_number = blur_image.split(\"_\")[0]\n",
    "\n",
    "                        if sharp_image_number == blurred_image_number:\n",
    "                            sharp_image = cv2.imread(os.path.join(path, image))\n",
    "                            blur_image = cv2.imread(os.path.join(blurred_image, blur_image))\n",
    "                            \n",
    "                            sharp_image = cv2.cvtColor(sharp_image, cv2.COLOR_BGR2RGB)\n",
    "                            blur_image = cv2.cvtColor(blur_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                            self.sharp_images.append(self.transforms()(Image.fromarray(sharp_image)))\n",
    "                            self.blurred_images.append(self.transforms()(Image.fromarray(blur_image)))\n",
    "                            \n",
    "                        else:\n",
    "                            continue\n",
    "                            \n",
    "            dataset = self.split_images(X = self.blurred_images, y = self.sharp_images)\n",
    "\n",
    "            return {\"data\": dataset, \"sharp\": self.sharp_images, \"blurred\": self.blurred_images}\n",
    "\n",
    "        else:\n",
    "            raise FileNotFoundError(\"The raw data folder does not exist. Please check the path and try again.\")\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        if os.path.exists(self.config[\"path\"][\"processed_path\"]):\n",
    "            \n",
    "            data = self.feature_extractor()\n",
    "            \n",
    "            train_dataloader = DataLoader(\n",
    "                dataset=list(zip(data[\"data\"][\"X_train\"], data[\"data\"][\"y_train\"])),\n",
    "                batch_size=self.batch_size, shuffle=True\n",
    "                )\n",
    "            \n",
    "            test_dataloader = DataLoader(\n",
    "                dataset=list(zip(data[\"data\"][\"X_test\"], data[\"data\"][\"y_test\"])),\n",
    "                batch_size=self.batch_size*16, shuffle=True\n",
    "            )\n",
    "            \n",
    "            dataloader = DataLoader(\n",
    "                dataset=list(zip(data[\"sharp\"], data[\"blurred\"])),\n",
    "                batch_size=self.batch_size, shuffle=True\n",
    "                )\n",
    "            \n",
    "            dump(\n",
    "                value=dataloader, filename=os.path.join(self.config[\"path\"][\"processed_path\"], \"dataloader.pkl\"))\n",
    "            \n",
    "            dump(\n",
    "                value=train_dataloader, filename=os.path.join(self.config[\"path\"][\"processed_path\"], \"train_dataloader.pkl\"))\n",
    "            \n",
    "            dump(\n",
    "                value=test_dataloader, filename=os.path.join(self.config[\"path\"][\"processed_path\"], \"test_dataloader.pkl\"))\n",
    "            \n",
    "        else:\n",
    "            raise FileNotFoundError(\"The processed data folder does not exist. Please check the path and try again.\")\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_images():\n",
    "        config = params()\n",
    "        \n",
    "        if os.path.exists(config[\"path\"][\"processed_path\"]):\n",
    "            plt.figure(figsize=(40, 15))\n",
    "            \n",
    "            test_dataloader = load(\n",
    "                filename=os.path.join(config[\"path\"][\"processed_path\"], \"test_dataloader.pkl\")\n",
    "                )\n",
    "            \n",
    "            blurred, sharp = next(iter(test_dataloader))\n",
    "            \n",
    "            for index, image in enumerate(sharp):\n",
    "                sharp_image = image.squeeze().permute(1, 2, 0).cpu().detach().numpy()\n",
    "                blurred_image = blurred[index].squeeze().permute(1, 2, 0).cpu().detach().numpy()\n",
    "                \n",
    "                sharp_image = (sharp_image - sharp_image.min())/(sharp_image.max() - sharp_image.min())\n",
    "                blurred_image = (blurred_image - blurred_image.min())/(blurred_image.max() - blurred_image.min())\n",
    "                \n",
    "                plt.subplot(2 * 4, 2 * 4, 2 * index + 1)\n",
    "                plt.imshow(sharp_image)\n",
    "                plt.title(\"Sharp\")\n",
    "                plt.axis(\"off\")\n",
    "                \n",
    "                plt.subplot(2 * 4, 2 * 4, 2 * index + 2)\n",
    "                plt.imshow(blurred_image)\n",
    "                plt.title(\"Blurred\")\n",
    "                plt.axis(\"off\")\n",
    "                \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            if os.path.exists(config[\"path\"][\"file_path\"]):\n",
    "                plt.savefig(os.path.join(config[\"path\"][\"file_path\"], \"images.jpg\"))\n",
    "                \n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            raise FileNotFoundError(\"The processed data folder does not exist. Please check the path and try again.\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def dataset_details():\n",
    "        config = params()\n",
    "        \n",
    "        if os.path.exists(config[\"path\"][\"processed_path\"]):\n",
    "            \n",
    "            dataloader = load(\n",
    "                filename=os.path.join(config[\"path\"][\"processed_path\"], \"dataloader.pkl\")\n",
    "                )\n",
    "            \n",
    "            test_dataloader = load(\n",
    "                filename=os.path.join(config[\"path\"][\"processed_path\"], \"test_dataloader.pkl\")\n",
    "                )\n",
    "            \n",
    "            train_dataloader = load(\n",
    "                filename=os.path.join(config[\"path\"][\"processed_path\"], \"train_dataloader.pkl\")\n",
    "                )\n",
    "            \n",
    "            train_data, train_label = next(iter(train_dataloader))\n",
    "            test_data, test_label = next(iter(test_dataloader))\n",
    "            \n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"total_data\": str(sum(sharp.size(0) for sharp, _ in dataloader)),\n",
    "                    \"total_train_data\": str(sum(sharp.size(0) for sharp, _ in train_dataloader)),\n",
    "                    \"total_test_data\": str(sum(sharp.size(0) for sharp, _ in test_dataloader)),\n",
    "                    \"train_data_shape\": str(train_data.size()),\n",
    "                    \"train_label_shape\": str(train_label.size()),\n",
    "                    \"test_data_shape\": str(test_data.size()),\n",
    "                    \"test_label_shape\": str(test_label.size())\n",
    "                },\n",
    "                index=[\"quantity\".title()]\n",
    "            ).T.to_csv(os.path.join(config[\"path\"][\"file_path\"], \"dataset_details.csv\"))\n",
    "        else:\n",
    "            raise FileNotFoundError(\"The processed data folder does not exist. Please check the path and try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loader = Loader(\n",
    "        image_path=\"/Users/shahmuhammadraditrahman/Desktop/dataset.zip\",\n",
    "        image_size=128,\n",
    "        split_size=0.20)\n",
    "    \n",
    "    loader.unzip_folder()\n",
    "    \n",
    "    loader.create_dataloader()\n",
    "    \n",
    "    loader.plot_images()\n",
    "    \n",
    "    print(loader.dataset_details())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels = 3, out_channels = 64):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel = 3\n",
    "        self.stride = 1\n",
    "        self.padding = 1\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.encoder = self.block()\n",
    "        \n",
    "    def block(self):\n",
    "        self.layers[\"conv\"] = nn.Conv2d(\n",
    "            in_channels=self.in_channels, out_channels=self.out_channels, kernel_size=self.kernel, stride=self.stride, padding=self.padding)\n",
    "        \n",
    "        self.layers[\"relu\"] = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layers[\"conv_1\"] = nn.Conv2d(\n",
    "            in_channels=self.out_channels, out_channels=self.out_channels, kernel_size=self.kernel, stride=self.stride, padding=self.padding)\n",
    "        \n",
    "        self.layers[\"batch_norm\"] = nn.BatchNorm2d(\n",
    "            num_features=self.out_channels)\n",
    "        \n",
    "        self.layers[\"relu_1\"] = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.layers[\"max_pool\"] = nn.MaxPool2d(kernel_size=(self.kernel//self.kernel)*2, stride=self.stride*2)\n",
    "        \n",
    "        return nn.Sequential(self.layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x is not None:\n",
    "            return self.encoder(x)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"The input must not be None.\".capitalize())\n",
    "        \n",
    "    @staticmethod\n",
    "    def total_params(model = None):\n",
    "        if model is not None:\n",
    "            return sum(params.numel() for params in model.parameters())\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"The model must not be None.\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    in_channels = 3\n",
    "    out_channels = 64\n",
    "    num_repetitive = 5\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    for _ in range(num_repetitive):\n",
    "        layers.append(EncoderBlock(in_channels=in_channels, out_channels=out_channels))\n",
    "\n",
    "        in_channels = out_channels\n",
    "        out_channels *= 2\n",
    "\n",
    "    model = nn.Sequential(*layers)\n",
    "\n",
    "    print(EncoderBlock.total_params(model=model))\n",
    "\n",
    "    print(summary(model=model, input_size=(3, 128, 128)))\n",
    "    \n",
    "    config = params()\n",
    "\n",
    "    draw_graph(model=model, input_size=(1, 3, 256, 256)).visual_graph.render(\n",
    "        filename=os.path.join(config[\"path\"][\"file_path\"], \"encoder_block\"), format=\"jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1          [-1, 512, 16, 16]       2,097,664\n",
      "            Conv2d-2          [-1, 512, 16, 16]       2,359,808\n",
      "              ReLU-3          [-1, 512, 16, 16]               0\n",
      "            Conv2d-4          [-1, 512, 16, 16]       2,359,808\n",
      "       BatchNorm2d-5          [-1, 512, 16, 16]           1,024\n",
      "              ReLU-6          [-1, 512, 16, 16]               0\n",
      "      DecoderBlock-7          [-1, 512, 16, 16]               0\n",
      "   ConvTranspose2d-8          [-1, 256, 32, 32]         524,544\n",
      "            Conv2d-9          [-1, 256, 32, 32]         590,080\n",
      "             ReLU-10          [-1, 256, 32, 32]               0\n",
      "           Conv2d-11          [-1, 256, 32, 32]         590,080\n",
      "      BatchNorm2d-12          [-1, 256, 32, 32]             512\n",
      "             ReLU-13          [-1, 256, 32, 32]               0\n",
      "     DecoderBlock-14          [-1, 256, 32, 32]               0\n",
      "  ConvTranspose2d-15          [-1, 128, 64, 64]         131,200\n",
      "           Conv2d-16          [-1, 128, 64, 64]         147,584\n",
      "             ReLU-17          [-1, 128, 64, 64]               0\n",
      "           Conv2d-18          [-1, 128, 64, 64]         147,584\n",
      "      BatchNorm2d-19          [-1, 128, 64, 64]             256\n",
      "             ReLU-20          [-1, 128, 64, 64]               0\n",
      "     DecoderBlock-21          [-1, 128, 64, 64]               0\n",
      "  ConvTranspose2d-22         [-1, 64, 128, 128]          32,832\n",
      "           Conv2d-23         [-1, 64, 128, 128]          36,928\n",
      "             ReLU-24         [-1, 64, 128, 128]               0\n",
      "           Conv2d-25         [-1, 64, 128, 128]          36,928\n",
      "      BatchNorm2d-26         [-1, 64, 128, 128]             128\n",
      "             ReLU-27         [-1, 64, 128, 128]               0\n",
      "     DecoderBlock-28         [-1, 64, 128, 128]               0\n",
      "  ConvTranspose2d-29          [-1, 3, 256, 256]             771\n",
      "             Tanh-30          [-1, 3, 256, 256]               0\n",
      "     DecoderBlock-31          [-1, 3, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 9,057,731\n",
      "Trainable params: 9,057,731\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 109.50\n",
      "Params size (MB): 34.55\n",
      "Estimated Total Size (MB): 144.30\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels = 1024, out_channels = 512, is_last = False):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.is_last = is_last\n",
    "        self.kernel = 2\n",
    "        self.stride = 2\n",
    "        self.padding = 0\n",
    "\n",
    "        self.layers = OrderedDict()\n",
    "        self.decoder = self.block()\n",
    "\n",
    "    def block(self):\n",
    "        self.layers[\"convTranspose\"] = nn.ConvTranspose2d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.kernel,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "\n",
    "        if self.is_last:\n",
    "            self.layers[\"Tanh\"] = nn.Tanh()\n",
    "        else:\n",
    "            self.layers[\"conv\"] = nn.Conv2d(\n",
    "                in_channels=self.out_channels,\n",
    "                out_channels=self.out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,  # Changed to maintain spatial dimensions\n",
    "            )\n",
    "            self.layers[\"relu\"] = nn.ReLU(inplace=True)\n",
    "\n",
    "            self.layers[\"conv_1\"] = nn.Conv2d(\n",
    "                in_channels=self.out_channels,\n",
    "                out_channels=self.out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,  # Changed to maintain spatial dimensions\n",
    "            )\n",
    "            self.layers[\"batch_norm\"] = nn.BatchNorm2d(num_features=self.out_channels)\n",
    "            self.layers[\"relu_1\"] = nn.ReLU(inplace=True)\n",
    "\n",
    "        return nn.Sequential(self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x is not None:\n",
    "            return self.decoder(x)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"The input must not be None.\".capitalize())\n",
    "\n",
    "    @staticmethod\n",
    "    def total_params(model = None):\n",
    "        if model is not None:\n",
    "            return sum(params.numel() for params in model.parameters())\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"The model must not be None.\".capitalize())\n",
    "\n",
    "    @staticmethod\n",
    "    def model_architecture(model=None):\n",
    "        config = params()\n",
    "        if model is not None:\n",
    "            if os.path.exists(config[\"path\"][\"file_path\"]):\n",
    "\n",
    "                draw_graph(\n",
    "                    model=model, input_size=(1, 3, 256, 256)\n",
    "                ).visual_graph.render(\n",
    "                    filename=os.path.join(config[\"path\"][\"file_path\"], \"decoder_block\"),\n",
    "                    format=\"jpg\",\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                raise FileNotFoundError(\n",
    "                    \"The processed data folder does not exist. Please check the path and try again.\"\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"The model must not be None.\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    in_channels = 1024\n",
    "    out_channels = 512\n",
    "    num_repetitive = 5\n",
    "    \n",
    "    layers = []\n",
    "    \n",
    "    for idx in range(num_repetitive):\n",
    "        layers.append(DecoderBlock(\n",
    "            in_channels=in_channels,\n",
    "            out_channels= 3 if idx == num_repetitive - 1 else out_channels,\n",
    "            is_last= True if idx == num_repetitive - 1 else False))\n",
    "        \n",
    "        in_channels = out_channels\n",
    "        out_channels //= 2\n",
    "        \n",
    "    model = nn.Sequential(*layers)\n",
    "    \n",
    "    print(model(torch.randn(1, 1024, 8, 8)).size())\n",
    "    \n",
    "    print(summary(model=model, input_size=(1024, 8, 8)))\n",
    "    \n",
    "    print(DecoderBlock.total_params(model=model))\n",
    "    \n",
    "    DecoderBlock.model_architecture(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
